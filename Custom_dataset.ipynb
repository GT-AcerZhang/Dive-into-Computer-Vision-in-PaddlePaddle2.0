{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 【动手学Paddle2.0系列】手把手教你自定义数据集\n",
    "\n",
    "\n",
    "本次将带领大家进行自定义数据集教程，并完整的走完整个项目流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压数据集，大家此处可以视自己的情况决定是不是要重新解压。\r\n",
    "!unzip -q data/data42610/foods.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1 数据集预处理\n",
    "\n",
    "\n",
    "此部分首先对数据集进行简单的整理，在food_data.csv中写入图像路径，以及对应的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "\r\n",
    "\r\n",
    "all_file_dir = 'foods'\r\n",
    "\r\n",
    "# f = open(r'train.txt', 'w')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "img_list = []\r\n",
    "label_list = []\r\n",
    "\r\n",
    "label_id = 0\r\n",
    "\r\n",
    "class_list = [c for c in os.listdir(all_file_dir) if os.path.isdir(os.path.join(all_file_dir, c))]\r\n",
    "\r\n",
    "# print(class_list)\r\n",
    "for class_dir in class_list:\r\n",
    "\r\n",
    "\r\n",
    "    image_path_pre = os.path.join(all_file_dir, class_dir)\r\n",
    "\r\n",
    "    for img in os.listdir(image_path_pre):\r\n",
    "        # print(img)\r\n",
    "        # f.write(\"{0}\\t{1}\\n\".format(os.path.join(image_path_pre, img), label_id))\r\n",
    "        img_list.append(os.path.join(image_path_pre, img))\r\n",
    "        label_list.append(label_id)\r\n",
    "    label_id += 1\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "生成包含数据集信息的csv文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "img_df =  pd.DataFrame(img_list)\r\n",
    "label_df = pd.DataFrame(label_list)\r\n",
    "\r\n",
    "img_df.columns = ['images']\r\n",
    "label_df.columns = ['label']\r\n",
    "\r\n",
    "df = pd.concat([img_df, label_df], axis=1)\r\n",
    "\r\n",
    "df = df.reindex(np.random.permutation(df.index))\r\n",
    "\r\n",
    "df.to_csv('food_data.csv', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "\r\n",
    "# 读取数据\r\n",
    "df = pd.read_csv('food_data.csv')\r\n",
    "image_path_list = df['images'].values\r\n",
    "label_list = df['label'].values\r\n",
    "\r\n",
    "# 划分训练集和校验集\r\n",
    "all_size = len(image_path_list)\r\n",
    "train_size = int(all_size * 0.8)\r\n",
    "train_image_path_list = image_path_list[:train_size]\r\n",
    "train_label_list = label_list[:train_size]\r\n",
    "val_image_path_list = image_path_list[train_size:]\r\n",
    "val_label_list = label_list[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2 自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "from paddle.io import Dataset\r\n",
    "import paddle.vision.transforms as T\r\n",
    "import paddle as pd\r\n",
    "\r\n",
    "class MyDataset(Dataset):\r\n",
    "    \"\"\"\r\n",
    "    步骤一：继承paddle.io.Dataset类\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, image, label, transform=None):\r\n",
    "        \"\"\"\r\n",
    "        步骤二：实现构造函数，定义数据读取方式，划分训练和测试数据集\r\n",
    "        \"\"\"\r\n",
    "        super(MyDataset, self).__init__()\r\n",
    "        # imgs = []\r\n",
    "        # f = open(txt, 'r')\r\n",
    "        # for line in f:\r\n",
    "        #     line = line.strip('\\n')\r\n",
    "        #     line = line.rstrip('\\n')\r\n",
    "        #     words = line.split()\r\n",
    "        #     imgs.append((words[0], int(words[1])))\r\n",
    "        imgs = image\r\n",
    "        labels = label\r\n",
    "        \r\n",
    "        self.labels = labels\r\n",
    "        self.imgs = imgs\r\n",
    "        self.transform = transform\r\n",
    "            # self.loader = loader\r\n",
    "    def __getitem__(self, index):  # 这个方法是必须要有的，用于按照索引读取每个元素的具体内容\r\n",
    "        fn = self.imgs\r\n",
    "        label = self.labels\r\n",
    "        # fn是图片path #fn和label分别获得imgs[index]也即是刚才每行中word[0]和word[1]的信息\r\n",
    "        for im,la in zip(fn, label):\r\n",
    "            img = Image.open(im)\r\n",
    "            img = img.convert(\"RGB\")\r\n",
    "            img =  np.array(img)\r\n",
    "            label = np.array([la]).astype(dtype='int64')\r\n",
    "        # 按照路径读取图片\r\n",
    "        if self.transform is not None:\r\n",
    "            img = self.transform(img)\r\n",
    "            # 数据标签转换为Tensor\r\n",
    "        return img, label\r\n",
    "        # return回哪些内容，那么我们在训练时循环读取每个batch时，就能获得哪些内容\r\n",
    "        # **********************************  #使用__len__()初始化一些需要传入的参数及数据集的调用**********************\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        # 这个函数也必须要写，它返回的是数据集的长度，也就是多少张图片，要和loader的长度作区分\r\n",
    "        return len(self.imgs)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "\r\n",
    "from paddle.metric import Accuracy\r\n",
    "from paddle.vision.models import resnet18\r\n",
    "\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "import warnings\r\n",
    "\r\n",
    "warnings.filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "\r\n",
    "import paddle.vision.transforms as T\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "transform = T.Compose([\r\n",
    "    T.Resize([224, 224]),\r\n",
    "    T.ToTensor(),\r\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\r\n",
    "    # T.Transpose(),\r\n",
    "])\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "train_dataset = MyDataset(image=train_image_path_list, label=train_label_list ,transform=transform)\r\n",
    "\r\n",
    "train_loader = paddle.io.DataLoader(train_dataset, places=paddle.CPUPlace(), batch_size=8, shuffle=True)\r\n",
    "\r\n",
    "# build model\r\n",
    "model = resnet18(pretrained=True, num_classes=102, with_pool=True)\r\n",
    "\r\n",
    "model = paddle.Model(model)\r\n",
    "optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4 模型训练&验证\n",
    "\n",
    "\n",
    "此步骤对模型进行训练，并保存为推理模型。（和checkpoint不同，注意区分）。\n",
    "\n",
    "\n",
    "此处仅进行了两次迭代，大家有兴趣可以自行调整迭代次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 配置模型\r\n",
    "model.prepare(\r\n",
    "    optim,\r\n",
    "    paddle.nn.CrossEntropyLoss(),\r\n",
    "    Accuracy(topk=(1, 2))\r\n",
    "    )\r\n",
    "\r\n",
    "model.fit(train_loader,\r\n",
    "        epochs=2,\r\n",
    "        verbose=1,\r\n",
    "        )\r\n",
    "\r\n",
    "model.evaluate(train_dataset, batch_size=8, verbose=1)\r\n",
    "\r\n",
    "\r\n",
    "model.save('inference_model', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5 模型预测推理\n",
    "\n",
    "\n",
    "在模型预测推理中，最后生成的CSV文件是一个较为通用的竞赛提交文件，大家可以根据自己的需要进行相应的更改。也算是一个小小的福利吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "import sys\r\n",
    "import paddle.fluid as fluid\r\n",
    "import paddle\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "paddle.enable_static()\r\n",
    "\r\n",
    "def load_img(img):\r\n",
    "    is_color = True\r\n",
    "    resize_size = 320\r\n",
    "    crop_size = 100  # 剪切尺寸，最后图片的size是这个值，不是resize_size\r\n",
    "    img = paddle.dataset.image.load_image(file=img, is_color=is_color)\r\n",
    "    img = paddle.dataset.image.simple_transform(im=img,\r\n",
    "                                                resize_size=resize_size, crop_size=crop_size,\r\n",
    "                                                is_color=is_color, is_train=False)\r\n",
    "    img = img.astype('float32') / 255.0\r\n",
    "    return img\r\n",
    "\r\n",
    "def pred_data(path_img_test):\r\n",
    "# 构建执行器\r\n",
    "    USE_GPU = False\r\n",
    "    place = fluid.CUDAPlace(0) if USE_GPU else fluid.CPUPlace()  # 使用CPU执行训练\r\n",
    "    infer_exe = fluid.Executor(place)\r\n",
    "    inference_scope = fluid.core.Scope()\r\n",
    "    # 载入model\r\n",
    "    with fluid.scope_guard(scope=inference_scope):\r\n",
    "        currentpath = os.path.dirname(sys.argv[0])\r\n",
    "        [inference_program,\r\n",
    "         feed_target_names,\r\n",
    "         fetch_targets] = fluid.io.load_inference_model(\r\n",
    "            dirname=os.path.join(currentpath, 'model_'), executor=infer_exe)\r\n",
    "\r\n",
    "        test_imgs_dir = path_img_test\r\n",
    "        img_data, img_paths, img_names = [], [], []\r\n",
    "        for img_name in os.listdir(test_imgs_dir):\r\n",
    "            img_path = os.path.join(test_imgs_dir, img_name)\r\n",
    "            img_paths.append(img_path)\r\n",
    "            img_data.append(load_img(img_path))\r\n",
    "            img_names.append(img_name.split('.')[0])\r\n",
    "        img_data = np.array(img_data).astype(\"float32\")\r\n",
    "\r\n",
    "        result = infer_exe.run(program=inference_program,\r\n",
    "                               feed={feed_target_names[0]: img_data},\r\n",
    "                               fetch_list=fetch_targets)\r\n",
    "    infer_label = [np.argmax(x) for x in result[0]]\r\n",
    "    class_dict = {0: 'neg', 1: 'pos'}\r\n",
    "    pred_class = []\r\n",
    "    for i in infer_label:\r\n",
    "        pred_class.append(class_dict[i])\r\n",
    "    submit = pd.DataFrame({'id': img_names, 'label': pred_class})\r\n",
    "    return submit\r\n",
    "\r\n",
    "def main(path_img_test, path_submit):\r\n",
    "    # 预测图片\r\n",
    "    result = pred_data(path_img_test)\r\n",
    "    # 写出预测结果\r\n",
    "    result.to_csv(path_submit, index=None, encoding='utf-8')\r\n",
    "\t\r\n",
    "if __name__ == \"__main__\":\r\n",
    "\r\n",
    "    path_img_test = 'foods/beef_carpaccio'\r\n",
    "    path_submit = 'test.csv'\r\n",
    "    main(path_img_test, path_submit)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 总结\n",
    "\n",
    "\n",
    "本次实践主要讲解一下如何自定义数据集，并对一个图像分类项目的完整流程进行了讲解。需要注意的几点如下：\n",
    "\n",
    "\n",
    "（1）在本项目中保存的是推理模型，和checkpoint是不同的，具体的讲解大家可以查看[官方API讲解](https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc/api/paddle/hapi/model/Model_cn.html)。\n",
    "\n",
    "\n",
    "（2）数据集中，label的类型需要是int64格式，并且需要扩充一个维度。\n",
    "\n",
    "\n",
    "（3）关于模型的详细训练过程讲解以及高层API的详细讲解，大家可以参考[Paddle2.0应用案例--迁移学习](https://aistudio.baidu.com/aistudio/projectdetail/1281706?shared=1)。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 一点小小的宣传\n",
    "\n",
    "\n",
    "我目前在上海，感兴趣的领域包括模型压缩、小目标检测、嵌入式，欢迎交流关注。[来AI Studio互粉吧~等你哦~ ](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/228777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
